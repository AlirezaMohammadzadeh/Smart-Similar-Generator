{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4e47fa",
   "metadata": {},
   "source": [
    "# Keyword Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d80db7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import spacy\n",
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "import itertools,Levenshtein\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a528695",
   "metadata": {},
   "source": [
    "api.load('word2vec-google-news-300')Will download word2vec google news dataset for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad089937",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affce3bc",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ef4fc",
   "metadata": {},
   "source": [
    "Word2vec is a technique for natural language processing published in 2013. The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953edbf8",
   "metadata": {},
   "source": [
    "Loading spacy English core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d0a2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de735203",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dad7cb",
   "metadata": {},
   "source": [
    "spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433d43e",
   "metadata": {},
   "source": [
    "Creating a googletrans object for detecting language of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "285cba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04b8a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(s):\n",
    "    if translator.detect(s).lang=='fa':\n",
    "        return 'fa'\n",
    "    if translator.detect(s).lang=='en':\n",
    "        return 'en'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f097f23",
   "metadata": {},
   "source": [
    "This function will remove prepositions (api.text-mining.ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ca2755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Information_Retrieval_persian(Word):\n",
    "    url =  baseUrl + \"InformationRetrieval/StopWordRemoval\"\n",
    "    payload = f'\"{Word}\"'\n",
    "    return(callApi(url, payload, tokenKey))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97944990",
   "metadata": {},
   "source": [
    "# api.text-minig.ir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283830ba",
   "metadata": {},
   "source": [
    "api.text-mining.ir is an api for advanced natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31b60c",
   "metadata": {},
   "source": [
    "Finding Synonyms for Persian words (api.text-mining.ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80082c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_Synonym_persian(Word):\n",
    "    url =  baseUrl + \"TextSimilarity/ExtractSynonyms\"\n",
    "    payload=f'\"{Word}\"'\n",
    "    return callApi(url, payload, tokenKey)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3568103",
   "metadata": {},
   "source": [
    "Split Product Name to Words by Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "479abdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(s):\n",
    "    doc=nlp(f\"{s}\")\n",
    "    doc=list(doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b12b9",
   "metadata": {},
   "source": [
    "Persian Text-Mining try except (api.text-mining.ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf3fa915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_mining():\n",
    "    try:\n",
    "        # Fix UTF8 output issues on Windows console.\n",
    "        # Does nothing if package is not installed\n",
    "        from win_unicode_console import enable\n",
    "        enable()\n",
    "    except ImportError:\n",
    "        text_minig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c3bb6",
   "metadata": {},
   "source": [
    "Decode Encode for Persian words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dab90ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utfReverse(s):\n",
    "    # CAVEAT: this will mess up characters that are\n",
    "    # more than 2 bytes long in utf 16\n",
    "    u = s.decode(\"utf-8\")\n",
    "    return u[::-1].encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6485c",
   "metadata": {},
   "source": [
    "Get token from text-mining API (api.text-mining.ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7e2cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Main Function #######################\n",
    "def callApi(url, data, tokenKey):    \n",
    "    headers = {\n",
    "        'Content-Type': \"application/json\",\n",
    "        'Authorization': \"Bearer \" + tokenKey,\n",
    "        'Cache-Control': \"no-cache\"\n",
    "    }\n",
    "    response = requests.request(\"POST\", url, data=data.encode(\"utf-8\"), headers=headers)\n",
    "    return response.text    # return utfReverse(response.text.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc14745",
   "metadata": {},
   "source": [
    "Creating pandas DataFrame for similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e12bd61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Word':['test'],\n",
    "     'Similar':['cream']}\n",
    "data_frame_similar=pd.DataFrame(data)\n",
    "data_frame_similar=data_frame_similar.drop(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60baba",
   "metadata": {},
   "source": [
    "Calling api.text-mining.ir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b27e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = \"http://api.text-mining.ir/api/\"\n",
    "url = baseUrl + \"Token/GetToken\"\n",
    "querystring = {\"apikey\":\"e99b418c-1c34-ed11-adba-98ded002619b\"}\n",
    "response = requests.request(\"GET\", url, params=querystring)\n",
    "data = json.loads(response.text)\n",
    "tokenKey = data['token']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b22fd",
   "metadata": {},
   "source": [
    "Return list of Persian synonyms anbd similars by api.text-mining.ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe72f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persian_similar(per_syn,data_frame_similar):\n",
    "    if len(per_syn)>3:\n",
    "        s=per_syn[1:len(per_syn)-1]\n",
    "        persian_similar_list=[]\n",
    "        i=0\n",
    "        while i < (len(s)):\n",
    "            word=''\n",
    "            if s[i]=='\"':\n",
    "                l=i+1\n",
    "                r=l+1\n",
    "                while r < (len(s)):\n",
    "                    if s[r]=='\"':\n",
    "                        break\n",
    "                    r=r+1\n",
    "                word=s[l:r]\n",
    "                l=r+2\n",
    "                persian_similar_list.append(word)\n",
    "                i=l\n",
    "        for i in persian_similar_list:\n",
    "            Persian_Similar=i\n",
    "            if orthographic_similarity(Word,Persian_Similar)==True:\n",
    "                data_frame_similar.loc[len(data_frame_similar.index)]=[Word,Persian_Similar]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6edc70e",
   "metadata": {},
   "source": [
    "calculate orthographic similarity between two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d0b61c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthographic_similarity(word,similar):\n",
    "    if Levenshtein.distance(word, similar)<=2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e4ac8",
   "metadata": {},
   "source": [
    "Read data from an excel(chosen words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "baeb1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_data_frame=pd.read_excel(\"chosen_words_100.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22d79e",
   "metadata": {},
   "source": [
    "Input HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f04976b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ProductNameWord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27505</td>\n",
       "      <td>Box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33143</td>\n",
       "      <td>Flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39926</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40020</td>\n",
       "      <td>Lite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44392</td>\n",
       "      <td>Note</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 ProductNameWord\n",
       "0       27505             Box\n",
       "1       33143           Flash\n",
       "2       39926          Huawei\n",
       "3       40020            Lite\n",
       "4       44392            Note"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e593553",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297145b4",
   "metadata": {},
   "source": [
    "Topn=? : Input number of similar words that you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5f481",
   "metadata": {},
   "source": [
    "List_Word_ProductName : Tokenize(ProductName):Split ProductName to words by Spacy library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec7d20",
   "metadata": {},
   "source": [
    "if len(Word)<2 : We dont execute Synonym Similar Algorithm for letters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e0a294",
   "metadata": {},
   "source": [
    "Word=Information_Retrieval_persian(Word): Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e9f23",
   "metadata": {},
   "source": [
    "per_syn = Text_Synonym_persian(Word): Get Persian similars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662432e",
   "metadata": {},
   "source": [
    "Inserting Persian similars to data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed836d3",
   "metadata": {},
   "source": [
    "result= wv.most_similar(positive=Word,topn=Topn) : Return Most Similar words (list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592ee9ae",
   "metadata": {},
   "source": [
    "result[i][1]>0.5: Checking if word and its similar are similar more than 50 percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63098886",
   "metadata": {},
   "source": [
    "orthographic_similarity(Word,English_Similar) Check if similar and Word are orthographicly same "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92949791",
   "metadata": {},
   "source": [
    "data_frame_similar.loc[len(data_frame_similar.index)]=[Word,English_Similar]:Insert English similar to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5163f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topn=20\n",
    "for i in range(len(word_data_frame)):\n",
    "    \n",
    "    Word=word_data_frame.iloc[i]['ProductNameWord']\n",
    "        \n",
    "    if len(Word)<2:\n",
    "        continue\n",
    "    if(detect_language(Word))=='fa':\n",
    "\n",
    "        Word=Information_Retrieval_persian(Word) \n",
    "    \n",
    "        per_syn = Text_Synonym_persian(Word) \n",
    "        \n",
    "        persian_similar(per_syn,data_frame_similar)\n",
    "        \n",
    "    elif(detect_language(Word))=='en':\n",
    "        try:\n",
    "            result= wv.most_similar(positive=Word,topn=Topn)\n",
    "            for i in range(Topn):\n",
    "                if result[i][1]>0.5:\n",
    "                    English_Similar=result[i][0]\n",
    "                    if orthographic_similarity(Word,English_Similar)==True:\n",
    "                        data_frame_similar.loc[len(data_frame_similar.index)]=[Word,English_Similar]\n",
    "        except:\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6385bf43",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c6fc7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Box</td>\n",
       "      <td>Boxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flash</td>\n",
       "      <td>flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lite</td>\n",
       "      <td>lite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samsungs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word   Similar\n",
       "0      Box     Boxes\n",
       "1    Flash     flash\n",
       "2     Lite      lite\n",
       "3  Samsung  Samsungs\n",
       "4  Samsung    Samung"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame_similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb70b5c",
   "metadata": {},
   "source": [
    "Import Keyword Alternatives to excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d50eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_similar.to_excel(\"KeywordAlternative.xlsx\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
